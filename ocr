import os, io, base64
import fitz
import httpx
import numpy as np
from PIL import Image, ImageOps, ImageFilter
import easyocr
import cv2
import fitz
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse, StreamingResponse
 
app = FastAPI()
reader = easyocr.Reader(["en","hi"], gpu=False)
 
EXTRACTOR_URL = "https://file-extractordev.sidbi.in/extract"
EXTRACTOR_TIMEOUT = 60.0
EXTRACTOR_FIELD_NAME = "file"
 
 
 
def clamp(v, lo, hi): return max(lo, min(hi, v))
 
def pil_to_png_bytes(pil_img):
    buf = io.BytesIO()
    pil_img.save(buf, format="PNG", optimize=True)
    return buf.getvalue()
 
def preprocess_for_compress_and_readability(pil_img):
    img = pil_img.convert("L")
    img = ImageOps.autocontrast(img)
    img = img.filter(ImageFilter.MedianFilter(size=3))
    img = img.filter(ImageFilter.UnsharpMask(radius=1.2, percent=130, threshold=3))
    return img
 
def resize_long_edge(pil_img, max_long_edge=1568):
    w, h = pil_img.size
    long_edge = max(w, h)
    if long_edge <= max_long_edge: return pil_img
    scale = max_long_edge / long_edge
    return pil_img.resize((int(w*scale), int(h*scale)), Image.LANCZOS)
 
def union_bbox_from_easyocr(results, conf_th=0.35):
    xs, ys = [], []
    for bbox, _, conf in results:
        if conf is None or conf < conf_th: continue
        for x, y in bbox:
            xs.append(float(x)); ys.append(float(y))
    if not xs: return None
    return min(xs), min(ys), max(xs), max(ys)
 
def fallback_bbox_nonwhite(gray, thr=245):
    mask = gray < thr
    if not mask.any(): return None
    ys, xs = np.where(mask)
    return float(xs.min()), float(ys.min()), float(xs.max()), float(ys.max())
 
def detect_card_bbox_connected_components(gray, thr=235, min_fill=0.55):
    try: import scipy.ndimage as ndi
    except: return fallback_bbox_nonwhite(gray)
    H, W = gray.shape
    mask = gray < thr
    if not mask.any(): return None
    bw = ndi.binary_opening(mask, iterations=1)
    bw = ndi.binary_closing(bw, iterations=1)
    labels, n = ndi.label(bw) # type: ignore
    if n == 0: return None
    objs = ndi.find_objects(labels)
    best, best_score = None, -1e18
    for idx, sl in enumerate(objs, start=1):
        if sl is None: continue
        ys, xs = sl
        y0, y1 = ys.start, ys.stop
        x0, x1 = xs.start, xs.stop
        area = (x1-x0)*(y1-y0)
        if area <= 0: continue
        fill = (labels[sl]==idx).sum()/area
        ar = (x1-x0)/max(1,(y1-y0))
        inv = max(ar, 1/max(ar,1e-6))
        area_ratio = area/(H*W)
        if not (0.008 <= area_ratio <= 0.55): continue
        if not (1.1 <= inv <= 3.2): continue
        if fill < min_fill: continue
        score = 3*fill - abs(inv-1.6) - abs(area_ratio-0.1)
        if score > best_score:
            best_score = score
            best = (float(x0), float(y0), float(x1), float(y1))
    return best
 
def detect_card_bbox_any_rotation(gray):
    H, W = gray.shape
    b = detect_card_bbox_connected_components(gray)
    if b: return b
    for k in (1,2,3):
        g = np.rot90(gray, k)
        b2 = detect_card_bbox_connected_components(g)
        if not b2: continue
        x0,y0,x1,y1 = b2
        if k==1: return W-1-y1, x0, W-1-y0, x1
        if k==2: return W-1-x1, H-1-y1, W-1-x0, H-1-y0
        if k==3: return y0, H-1-x1, y1, H-1-x0
    return None
 
def extract_card(pil_img):
    gray = np.array(pil_img.convert("L"))
    work = gray.copy()
    for _ in range(3):
        b = detect_card_bbox_any_rotation(work)
        if not b:
            ocr = reader.readtext(np.array(pil_img))
            b = union_bbox_from_easyocr(ocr)
            if not b: return None
        x0,y0,x1,y1 = map(int,b)
        crop = pil_img.crop((x0,y0,x1,y1))
        if crop.width > 200 and crop.height > 120:
            return crop
        work[y0:y1,x0:x1] = 255
    return None
 
async def extractor(file_bytes: bytes, filename: str, content_type: str):
    #extract from vishnu api
    #return api's response.
   
    async with httpx.AsyncClient(timeout=EXTRACTOR_TIMEOUT, verify=False) as client:
            files = {"file": (filename, file_bytes, content_type)}
            resp = await client.post(EXTRACTOR_URL, files=files)
 
    if resp.status_code < 200 or resp.status_code >= 300:
        try:
            detail = resp.json()
        except Exception:
            detail = resp.text
        raise RuntimeError(f"ExtractorDev error {resp.status_code}: {detail}")
    return resp.json()
 
def blur_score(img):
    return cv2.Laplacian(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY),cv2.CV_64F).var()
 
def edge_density(img):
    return cv2.Canny(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY),80,160).mean()
 
def contrast(img):
    return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY).std()
 
def glare(img):
    return (cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) > 245).mean()
 
def quality_check(img):
    h,w = img.shape[:2]
    if h < 300 or w < 300:
        return False,(
            "Image is too small/low resolution. Please re-upload a clearer photo (min 300×300) "
            "and make sure the full card is visible (all edges). "
            "Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."
        )

    ocr = reader.readtext(img)
    if not ocr:
        return False,(
            "No readable text found. Please upload a clear photo with the full card visible (all edges). "
            "Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."
        )
    
    confs, blurs, edges, conts = [],[],[],[]
    for b,_,c in ocr:
        (x0,y0),(x1,y1) = b[0],b[2]
        roi = img[int(y0):int(y1),int(x0):int(x1)]
        if roi.size == 0: continue
        confs.append(c)
        blurs.append(blur_score(roi))
        edges.append(edge_density(roi))
        conts.append(contrast(roi))
    if not confs: 
        return False,(
            "No readable text found. Please upload a clear photo with the full card visible (all edges). "
            "Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."
        )

    if np.median(confs) < 0.45:
        return False,(
            "Text is not clear enough to read. Please retake in better lighting and avoid shadows. "
            "Also ensure the full card is visible (all edges). "
            "Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."
        )

    if np.median(blurs) < 20:
        return False,(
            "Text is not clear enough to read. Please retake in better lighting and avoid shadows. "
            "Also ensure the full card is visible (all edges). "
            "Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."
        )

    if np.median(edges) < 5: 
        return False,(
            "Image is blurry. Hold steady, tap to focus on the text, and retake the photo. "
            "Also ensure the full card is visible (all edges). "
            "Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."
        )

    if np.median(conts) < 28: 
        return False,(
            "Text contrast is too low. Please use better lighting and avoid dark/colored backgrounds. "
            "Also ensure the full card is visible (all edges). "
            "Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."
        )

    if glare(img) > 0.12: 
        return False,(
            "Glare detected. Tilt the camera slightly or move away from direct light and retake. "
            "Also ensure the full card is visible (all edges). "
            "Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."
        )

    return True,None

@app.post("/process")
async def process(file: UploadFile = File(...)):
    ext = file.filename.split(".")[-1].lower()
    raw = await file.read()
    if ext not in ["pdf","jpg","jpeg","png"]:
        return JSONResponse({"status":"failure","reason":"Invalid file type. Please upload either one of pdf, jpg, jpeg or png"})
    if ext=="pdf":
        try:
            doc = fitz.open(stream=raw, filetype="pdf")
        except:
            return JSONResponse({"status": "failure", "reason": "Decoding failed. Please retry again."})
        if len(doc)> 1:
            try:
                extractor_json = await extractor(
                                    file_bytes=raw,
                                    filename=file.filename,
                                    content_type="application/pdf"
                                )
                return JSONResponse({"status": "success", "data": extractor_json})
            except Exception as e:
                return JSONResponse({"status": "failure", "reason": "extractor_failed", "detail": str(e)})
       
        page = doc[0]
        zoom = 200/72
        mat = fitz.Matrix(zoom,zoom)
       
        pix = page.get_pixmap(matrix=mat, alpha=False) 
        img = Image.open(io.BytesIO(pix.tobytes("png"))).convert("RGB")
    else:
        try:
            img = Image.open(io.BytesIO(raw)).convert("RGB")
        except:
            return JSONResponse({"status":"failure","reason":"Decoding failed. Please retry again."})
 
    card = extract_card(img)
    if not card:
        return JSONResponse({"status": "failure", "reason": "Card not detected. Please make sure all edges of the cards are visible. Note: Retake/re-upload in better quality—good lighting, sharp focus, no shadows/glare."})
 
    card = preprocess_for_compress_and_readability(card)
    card = resize_long_edge(card)
 
    cv_img = cv2.cvtColor(np.array(card), cv2.COLOR_GRAY2BGR)
    ok, reason = quality_check(cv_img)
    if not ok:
        return JSONResponse({"status": "failure", "reason": reason})
   
    img_bytes = pil_to_png_bytes(card)
    try:
        extractor_json = await extractor(
            file_bytes=img_bytes,
            filename="card.png",
            content_type="image/png"
        )
        return JSONResponse({"status": "success", "data": extractor_json})
    except Exception as e:
        return JSONResponse({"status": "failure", "reason": "extractor_failed", "detail": str(e)})
 
